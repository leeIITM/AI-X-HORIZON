{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leeIITM/AI-X-HORIZON/blob/main/YOLO_V11_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av5Rzmqwg18y",
        "outputId": "82975721-29cc-4a30-aacc-605fa8b02cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan  2 06:07:01 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a4RLYAPhVdq"
      },
      "source": [
        "## Getting the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKSeg5UvhmMg",
        "outputId": "5f0b20ea-2638-4c49-bde8-ed6028e2749d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.50-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.12.14)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.55.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
            "Downloading roboflow-1.1.50-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, idna, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 roboflow-1.1.50\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g9qJL0whKT4",
        "outputId": "9e43f09d-cf3a-4632-d129-3ff57d89f884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in SUAV-Yolo-1 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156607/156607 [00:02<00:00, 56829.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to SUAV-Yolo-1 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3098/3098 [00:00<00:00, 4030.30it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"EX5EQLCiwLSmjjZIBJkc\")\n",
        "project = rf.workspace(\"robot001\").project(\"suav-yolo-u8szd\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LgjbCFDiANK"
      },
      "source": [
        "Installing YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqzJVZmfiBuB",
        "outputId": "4060ea5b-7736-40a7-cac2-00816510100a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 32.9/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install \"ultralytics<=8.3.40\" supervision roboflow\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kizD87bGh2yj",
        "outputId": "bf0ec2d6-0c2d-439a-a63d-d741e0442a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.55 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.40 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11s.pt, data=/content/SUAV-Yolo-1/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Overriding model.yaml nc=80 with nc=18\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    826374  ultralytics.nn.modules.head.Detect           [18, [128, 256, 512]]         \n",
            "YOLO11s summary: 319 layers, 9,434,758 parameters, 9,434,742 gradients, 21.6 GFLOPs\n",
            "\n",
            "Transferred 493/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/SUAV-Yolo-1/train/labels.cache... 1473 images, 0 backgrounds, 0 corrupt: 100% 1473/1473 [00:00<?, ?it/s]\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 1740, len(boxes) = 5083. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/SUAV-Yolo-1/valid/labels.cache... 45 images, 0 backgrounds, 0 corrupt: 100% 45/45 [00:00<?, ?it/s]\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 35, len(boxes) = 115. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000455, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10      4.61G      1.206      3.488      1.238          1        640: 100% 93/93 [00:38<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.04it/s]\n",
            "                   all         45        115      0.679       0.58      0.645      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10      4.44G      1.164       1.66      1.189          1        640: 100% 93/93 [00:35<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.59it/s]\n",
            "                   all         45        115      0.613      0.608      0.637      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10      4.45G      1.151      1.391      1.204          1        640: 100% 93/93 [00:32<00:00,  2.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.70it/s]\n",
            "                   all         45        115      0.482      0.632       0.64      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10      4.45G      1.125      1.163      1.161          2        640: 100% 93/93 [00:32<00:00,  2.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.30it/s]\n",
            "                   all         45        115      0.516      0.725      0.723      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10      4.41G      1.023     0.9837      1.119          1        640: 100% 93/93 [00:33<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  4.09it/s]\n",
            "                   all         45        115      0.722      0.638      0.757      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10      4.44G      1.022     0.8639      1.114          1        640: 100% 93/93 [00:34<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.50it/s]\n",
            "                   all         45        115      0.822      0.691      0.886      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10      4.45G     0.9827     0.7779      1.096          1        640: 100% 93/93 [00:35<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.83it/s]\n",
            "                   all         45        115      0.864      0.705      0.898      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10      4.45G     0.8919     0.6704      1.041          2        640: 100% 93/93 [00:35<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.55it/s]\n",
            "                   all         45        115      0.723      0.783      0.852       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10       4.4G     0.8453     0.6098      1.013          2        640: 100% 93/93 [00:34<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.31it/s]\n",
            "                   all         45        115      0.867      0.856      0.952       0.74\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/10      4.45G     0.7954     0.5679     0.9895          1        640: 100% 93/93 [00:34<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.23it/s]\n",
            "                   all         45        115      0.875      0.863      0.961      0.749\n",
            "\n",
            "10 epochs completed in 0.104 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 19.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 19.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.40 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11s summary (fused): 238 layers, 9,419,766 parameters, 0 gradients, 21.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.26it/s]\n",
            "                   all         45        115      0.875      0.863      0.961      0.748\n",
            "               BSVBall          1          1      0.668          1      0.995      0.995\n",
            "           BaseballBat          7          7          1      0.747      0.995      0.691\n",
            "                   Bed          4          4          1      0.875      0.995      0.948\n",
            "                   Bus          2          3      0.841      0.667      0.712      0.519\n",
            "                   Car          1          1      0.822          1      0.995      0.398\n",
            "              Football          2          2      0.826          1      0.995      0.995\n",
            "              Mattress          2          2      0.806          1      0.995      0.921\n",
            "             Motorbike          1          2          1      0.731      0.995      0.647\n",
            "                Person          4         47       0.82      0.787      0.852      0.586\n",
            "                 Plane          3          6          1      0.648      0.894      0.534\n",
            "                  Ship          4          4      0.907          1      0.995      0.664\n",
            "             Snowboard          1          1      0.726          1      0.995      0.796\n",
            "              StopSign          5          6      0.801          1      0.995      0.969\n",
            "              Suitcase          4          4      0.913          1      0.995      0.893\n",
            "          TennisRacket          3          7          1      0.965      0.995      0.969\n",
            "       Umbrella-Closed          1          1      0.745          1      0.995      0.497\n",
            "         Umbrella-Open          2         17          1       0.25      0.936      0.694\n",
            "Speed: 0.2ms preprocess, 4.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!yolo task=detect mode=train model=yolo11s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIp3k4MAlSMe",
        "outputId": "3c5aced1-e8fc-4b76-f79d-99483ed93fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11s summary (fused): 238 layers, 9,419,766 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/SUAV-Yolo-1/test/labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% 25/25 [00:00<?, ?it/s]\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 29, len(boxes) = 51. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.11it/s]\n",
            "                   all         25         51       0.83      0.797      0.864      0.749\n",
            "               BSVBall          3          3          1      0.831      0.995      0.995\n",
            "                   Bed          3          3      0.902          1      0.995      0.863\n",
            "                   Bus          1          2      0.486        0.5      0.595      0.422\n",
            "                   Car          1          6          1      0.755      0.995      0.895\n",
            "              Football          1          1      0.316          1      0.995      0.895\n",
            "              Mattress          3          3       0.91          1      0.995       0.79\n",
            "                Person          2         19      0.825      0.746      0.818      0.592\n",
            "              StopSign          4          5      0.795          1      0.995      0.934\n",
            "              Suitcase          5          5      0.939          1      0.995       0.96\n",
            "          TennisRacket          2          2          1       0.73      0.995      0.748\n",
            "       Umbrella-Closed          1          1          1          0          0          0\n",
            "         Umbrella-Open          1          1      0.787          1      0.995      0.895\n",
            "Speed: 0.2ms preprocess, 23.6ms inference, 0.0ms loss, 32.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=val model=\"/content/runs/detect/train2/weights/best.pt\" data={dataset.location}/data.yaml split=test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_zip_file = \"/content/drive/MyDrive/test.zip\"\n"
      ],
      "metadata": {
        "id": "91yj9Wm2-0Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "images_dir = \"/content/test_images/images\"\n",
        "\n",
        "\n",
        "if not os.path.exists(images_dir):\n",
        "    raise FileNotFoundError(f\"The directory {images_dir} does not exist. Please check the path.\")\n",
        "\n",
        "\n",
        "model = YOLO(\"/content/runs/detect/train/weights/best.pt\")\n",
        "\n",
        "results = model.predict(source=images_dir, save=True,conf = 0.2, imgsz=640)\n",
        "\n",
        "\n",
        "output_dir = \"runs/detect/predict\"\n",
        "print(f\"Inference complete. Results saved in: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2mi8fhdAUEX",
        "outputId": "64f29e95-9062-49b7-8d01-69861c9de5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/6 /content/test_images/images/bike_1.jpg: 384x640 (no detections), 11.3ms\n",
            "image 2/6 /content/test_images/images/bike_2.jpg: 384x640 (no detections), 10.7ms\n",
            "image 3/6 /content/test_images/images/bike_topview.jpg: 384x640 (no detections), 10.7ms\n",
            "image 4/6 /content/test_images/images/car.jpg: 384x640 1 Car, 10.7ms\n",
            "image 5/6 /content/test_images/images/car_1.jpg: 384x640 (no detections), 10.7ms\n",
            "image 6/6 /content/test_images/images/car_topview.jpg: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict10\u001b[0m\n",
            "Inference complete. Results saved in: runs/detect/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to the folder you want to download\n",
        "folder_to_download = '/content/runs/detect/train2'  # Replace with your folder path\n",
        "zip_file_name = '/content/trainq2.zip'   # Output zip file\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(base_name=zip_file_name.replace('.zip', ''), format='zip', root_dir=folder_to_download)\n",
        "print(f\"Folder zipped as: {zip_file_name}\")\n",
        "\n",
        "# Download the zipped folder\n",
        "files.download(zip_file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YinfWm8MCJZg",
        "outputId": "b1e8117a-77fc-494c-c073-0a6ae75e60b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder zipped as: /content/trainq2.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5c706d92-5556-49a3-a72a-2e5ce3183505\", \"trainq2.zip\", 41100875)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "images_dir = \"/content/test_images/images\"\n",
        "\n",
        "\n",
        "if not os.path.exists(images_dir):\n",
        "    raise FileNotFoundError(f\"The directory {images_dir} does not exist. Please check the path.\")\n",
        "\n",
        "\n",
        "model = YOLO(\"/content/runs/detect/train/weights/best.pt\")\n",
        "\n",
        "results = model.predict(source=images_dir, save=True,conf = 0.05, imgsz=640)\n",
        "\n",
        "\n",
        "output_dir = \"runs/detect/predict\"\n",
        "print(f\"Inference complete. Results saved in: {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aLqF0d9BWh9",
        "outputId": "cc5fe3ad-1b6a-4f49-9f46-35bc7d211610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/6 /content/test_images/images/bike_1.jpg: 384x640 (no detections), 14.6ms\n",
            "image 2/6 /content/test_images/images/bike_2.jpg: 384x640 (no detections), 14.1ms\n",
            "image 3/6 /content/test_images/images/bike_topview.jpg: 384x640 (no detections), 11.5ms\n",
            "image 4/6 /content/test_images/images/car.jpg: 384x640 1 Car, 16.3ms\n",
            "image 5/6 /content/test_images/images/car_1.jpg: 384x640 (no detections), 15.1ms\n",
            "image 6/6 /content/test_images/images/car_topview.jpg: 384x640 (no detections), 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict7\u001b[0m\n",
            "Inference complete. Results saved in: runs/detect/predict\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}